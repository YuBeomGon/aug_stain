{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e4aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataset import val_transforms, CDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f1ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch_size\": 64, \n",
    "                          \"epochs\": 40, \n",
    "                          \"data\": 0, \n",
    "                          'lr':0.02,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':0,\n",
    "                          'workers':16,\n",
    "                         'print_freq':2000,\n",
    "                         'saved_dir':'../trained_models/checkpoint.pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f5ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make saved dir\n",
    "from pathlib import Path\n",
    "path = Path(args.saved_dir.split('checkpoint')[0])\n",
    "path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d1b194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print(ngpus_per_node)\n",
    "GPU_NUM = args.gpu # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c55e114-1622-42c4-9ce1-e1835910c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from augment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e52944",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=.8),\n",
    "        A.VerticalFlip(p=.8),\n",
    "        A.RandomRotate90(p=.8)]\n",
    "    ),\n",
    "    # A.OneOf([\n",
    "    #     HEColorAugment(sigma1=.2, sigma2=2., mat=None, p=0.9),\n",
    "    #     HEColorAugment(sigma1=.4, sigma2=5., mat=None, p=0.9),\n",
    "    #     HEColorAugment(sigma1=.6, sigma2=5., mat=None, p=0.9)\n",
    "    # ]),\n",
    "], p=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732a5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "\n",
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, defaultpath='/home/beomgon/Dataset/new_patches/', transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.dir = defaultpath\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.iloc[idx, 4]\n",
    "#         print(pid)\n",
    "\n",
    "        image = cv2.imread(self.dir + path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image = (image.astype(np.float32)-128.)/128.\n",
    "        \n",
    "#         if image is uint8, normalization by 255 is done automatically by albumebtation(ToTensor method)\n",
    "        if self.transform:\n",
    "            timage = self.transform(image=image)\n",
    "            image = timage['image']\n",
    "        \n",
    "        image =  torch.tensor(image, dtype=torch.float32)/255.\n",
    "        #image = (torch.tensor(image, dtype=torch.float32)-128)/128\n",
    "        image = image.permute(2,0,1)\n",
    "            \n",
    "        label = self.df.iloc[idx, 5]\n",
    "        return image, label, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada50d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../dataframe/train_New_Stomach_df.csv')\n",
    "train_dataset = CDataset(train_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/', \n",
    "                         transform=train_transforms)\n",
    "\n",
    "val_df = pd.read_csv('../dataframe/val_New_Stomach_df.csv')\n",
    "val_dataset = CDataset(val_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/',\n",
    "                       transform=val_transforms)  \n",
    "\n",
    "test_df = pd.read_csv('../dataframe/test_New_Stomach_df.csv')\n",
    "test_dataset = CDataset(test_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/',\n",
    "                        transform=val_transforms)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfca7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label, path = next(iter(train_dataset))\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6787059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dffcb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels, paths = next(iter(train_loader))\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccf8f5-24fb-4986-9ad0-91ce95498912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f0d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "from resnet import resnet152, resnet18\n",
    "model = resnet18(pretrained=False)\n",
    "model.fc = nn.Linear(16, 3)\n",
    "torch.nn.init.normal_(model.fc.weight, std=0.01)\n",
    "torch.nn.init.constant_(model.fc.bias, 0.)\n",
    "default_state_dict = model.state_dict()\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.Adam(params, lr=0.01, weight_decay=args.weight_decay)\n",
    "optimizer = torch.optim.SGD(\n",
    "       params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = torch.optim.SGD(params, lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30], \n",
    "                                                    gamma=0.2)\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7495c52-9f8b-40d7-86e0-b18e0b923d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [  0/406]\tTime  1.384 ( 1.384)\tLoss 3.6756e-01 (3.6756e-01)\tAcc@1  87.50 ( 87.50)\n",
      " * Acc@1 90.493\n",
      "Test: [  0/406]\tTime  1.374 ( 1.374)\tLoss 2.8977e-01 (2.8977e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 89.900\n",
      "Test: [  0/406]\tTime  1.321 ( 1.321)\tLoss 2.7304e-01 (2.7304e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 90.713\n",
      "Test: [  0/406]\tTime  1.159 ( 1.159)\tLoss 1.9268e-01 (1.9268e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 90.605\n",
      "Test: [  0/406]\tTime  1.302 ( 1.302)\tLoss 2.4541e-01 (2.4541e-01)\tAcc@1  93.75 ( 93.75)\n",
      " * Acc@1 90.671\n",
      "Test: [  0/406]\tTime  1.198 ( 1.198)\tLoss 5.3538e-01 (5.3538e-01)\tAcc@1  85.94 ( 85.94)\n",
      " * Acc@1 90.621\n",
      "Test: [  0/406]\tTime  1.174 ( 1.174)\tLoss 2.9040e-01 (2.9040e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 90.559\n",
      "Test: [  0/406]\tTime  1.168 ( 1.168)\tLoss 3.3278e-01 (3.3278e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 90.786\n",
      "Test: [  0/406]\tTime  1.364 ( 1.364)\tLoss 4.1314e-01 (4.1314e-01)\tAcc@1  85.94 ( 85.94)\n",
      " * Acc@1 90.362\n",
      "Test: [  0/406]\tTime  1.068 ( 1.068)\tLoss 3.0331e-01 (3.0331e-01)\tAcc@1  87.50 ( 87.50)\n",
      " * Acc@1 90.624\n",
      "Test: [  0/406]\tTime  1.338 ( 1.338)\tLoss 2.7021e-01 (2.7021e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 90.590\n",
      "Test: [  0/406]\tTime  1.093 ( 1.093)\tLoss 1.5947e-01 (1.5947e-01)\tAcc@1  95.31 ( 95.31)\n",
      " * Acc@1 90.725\n",
      "Test: [  0/406]\tTime  1.332 ( 1.332)\tLoss 1.9486e-01 (1.9486e-01)\tAcc@1  95.31 ( 95.31)\n",
      " * Acc@1 90.717\n",
      "Test: [  0/406]\tTime  1.439 ( 1.439)\tLoss 1.5211e-01 (1.5211e-01)\tAcc@1  93.75 ( 93.75)\n",
      " * Acc@1 90.493\n",
      "Test: [  0/406]\tTime  1.364 ( 1.364)\tLoss 2.9269e-01 (2.9269e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 90.798\n",
      "Test: [  0/406]\tTime  1.406 ( 1.406)\tLoss 2.8254e-01 (2.8254e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 90.482\n",
      "Test: [  0/406]\tTime  1.303 ( 1.303)\tLoss 1.7924e-01 (1.7924e-01)\tAcc@1  96.88 ( 96.88)\n",
      " * Acc@1 89.900\n",
      "Test: [  0/406]\tTime  1.051 ( 1.051)\tLoss 3.2813e-01 (3.2813e-01)\tAcc@1  81.25 ( 81.25)\n",
      " * Acc@1 90.563\n",
      "Test: [  0/406]\tTime  1.632 ( 1.632)\tLoss 3.2731e-01 (3.2731e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 90.312\n",
      "Test: [  0/406]\tTime  1.385 ( 1.385)\tLoss 4.4968e-01 (4.4968e-01)\tAcc@1  82.81 ( 82.81)\n",
      " * Acc@1 90.597\n",
      "Test: [  0/406]\tTime  1.301 ( 1.301)\tLoss 2.6109e-01 (2.6109e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 90.740\n",
      "Test: [  0/406]\tTime  1.430 ( 1.430)\tLoss 2.0986e-01 (2.0986e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 90.863\n",
      "Test: [  0/406]\tTime  1.464 ( 1.464)\tLoss 2.6885e-01 (2.6885e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 90.501\n",
      "Test: [  0/406]\tTime  1.167 ( 1.167)\tLoss 4.5379e-01 (4.5379e-01)\tAcc@1  85.94 ( 85.94)\n",
      " * Acc@1 90.632\n",
      "Test: [  0/406]\tTime  1.156 ( 1.156)\tLoss 3.7264e-01 (3.7264e-01)\tAcc@1  87.50 ( 87.50)\n",
      " * Acc@1 90.709\n",
      "Test: [  0/406]\tTime  1.571 ( 1.571)\tLoss 2.7025e-01 (2.7025e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 90.509\n",
      "Test: [  0/406]\tTime  1.457 ( 1.457)\tLoss 2.3033e-01 (2.3033e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 90.555\n",
      "Test: [  0/406]\tTime  1.378 ( 1.378)\tLoss 3.1773e-01 (3.1773e-01)\tAcc@1  84.38 ( 84.38)\n",
      " * Acc@1 90.528\n",
      "Test: [  0/406]\tTime  1.639 ( 1.639)\tLoss 2.1519e-01 (2.1519e-01)\tAcc@1  87.50 ( 87.50)\n",
      " * Acc@1 90.586\n",
      "Test: [  0/406]\tTime  1.489 ( 1.489)\tLoss 8.8288e-02 (8.8288e-02)\tAcc@1  93.75 ( 93.75)\n",
      " * Acc@1 90.389\n",
      "Test: [  0/406]\tTime  1.466 ( 1.466)\tLoss 1.4759e-01 (1.4759e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 90.509\n",
      "Test: [  0/406]\tTime  1.349 ( 1.349)\tLoss 4.5906e-01 (4.5906e-01)\tAcc@1  87.50 ( 87.50)\n",
      " * Acc@1 90.590\n",
      "Test: [  0/406]\tTime  1.158 ( 1.158)\tLoss 3.7338e-01 (3.7338e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 90.651\n",
      "Test: [  0/406]\tTime  1.042 ( 1.042)\tLoss 1.5812e-01 (1.5812e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 90.366\n",
      "Test: [  0/406]\tTime  1.192 ( 1.192)\tLoss 1.5702e-01 (1.5702e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 90.786\n",
      "Test: [  0/406]\tTime  1.485 ( 1.485)\tLoss 1.0798e-01 (1.0798e-01)\tAcc@1  95.31 ( 95.31)\n",
      " * Acc@1 90.559\n",
      "Test: [  0/406]\tTime  1.517 ( 1.517)\tLoss 3.3127e-01 (3.3127e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 90.409\n",
      "Test: [  0/406]\tTime  1.063 ( 1.063)\tLoss 3.8968e-01 (3.8968e-01)\tAcc@1  81.25 ( 81.25)\n",
      " * Acc@1 90.547\n",
      "Test: [  0/406]\tTime  1.412 ( 1.412)\tLoss 1.9975e-01 (1.9975e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 90.428\n",
      "Test: [  0/406]\tTime  1.104 ( 1.104)\tLoss 3.3029e-01 (3.3029e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 90.382\n"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "\n",
    "model = resnet18(pretrained=False, linear_evaluation=True)\n",
    "model.fc = nn.Linear(16, 3)\n",
    "args.saved_dir = '../trained_models/resnet8/cus_stomach4_' + str(1) + '/checkpoint.pt'\n",
    "checkpoint = torch.load(args.saved_dir)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.train()\n",
    "for p in model.parameters() :\n",
    "    p.requires_grad = False\n",
    "model.fc.weight.requires_grad = True\n",
    "model.fc.bias.requires_grad = True\n",
    "model.to(device)\n",
    "\n",
    "best_acc1 = 0\n",
    "acc1 = 0\n",
    "\n",
    "optimizer = torch.optim.Adam(params, lr=0.001, weight_decay=args.weight_decay)\n",
    "\n",
    "# acc1 = validate(val_loader, model, criterion, args)   \n",
    "# print('acc1', acc1)\n",
    "\n",
    "for epoch in range(args.epochs) :\n",
    "    model.train()\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30], \n",
    "                                                        gamma=0.3)    \n",
    "    scheduler.step()\n",
    "    for i, (images, targets, _) in enumerate(train_loader):\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            images = images.cuda(args.gpu, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            targets = targets.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, targets)    \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "        \n",
    "    # evaluate after every epoch\n",
    "    acc1 = validate(val_loader, model, criterion, args)   \n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1) \n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "        'scheduler' : scheduler.state_dict(),\n",
    "    }, is_best, filename=args.saved_dir)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46040a12-571d-4a9a-b095-a443c4226c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [  0/237]\tTime  1.254 ( 1.254)\tLoss 1.2496e-01 (1.2496e-01)\tAcc@1  93.75 ( 93.75)\n",
      " * Acc@1 92.883\n"
     ]
    }
   ],
   "source": [
    "args.saved_dir = '../trained_models/resnet8/cus_stomach4_' + str(1) + '/checkpoint.pt'\n",
    "checkpoint = torch.load(args.saved_dir)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "acc1 = validate(test_loader, model, criterion, args)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19e91334-613b-4ec9-ac86-58cedce71537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [  0/406]\tTime  1.386 ( 1.386)\tLoss 4.7145e-01 (4.7145e-01)\tAcc@1  85.94 ( 85.94)\n",
      " * Acc@1 90.863\n"
     ]
    }
   ],
   "source": [
    "acc1 = validate(val_loader, model, criterion, args)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f64ba-c263-44cc-bd59-bb6e59286319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
