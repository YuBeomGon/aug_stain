{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e4aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataset import val_transforms, CDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f1ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch_size\": 128, \n",
    "                          \"epochs\": 50, \n",
    "                          \"data\": 0, \n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':2,\n",
    "                          'workers':16,\n",
    "                         'print_freq':2000,\n",
    "                         'saved_dir':'../trained_models/checkpoint.pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f5ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make saved dir\n",
    "from pathlib import Path\n",
    "path = Path(args.saved_dir.split('checkpoint')[0])\n",
    "path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d1b194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "cuda:2\n"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print(ngpus_per_node)\n",
    "GPU_NUM = args.gpu # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c55e114-1622-42c4-9ce1-e1835910c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from augment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e52944",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=.8),\n",
    "        A.VerticalFlip(p=.8),\n",
    "        A.RandomRotate90(p=.8)]\n",
    "    ),\n",
    "    # HEColorAugment(sigma1=.4, sigma2=5., mat=None, p=0.9),\n",
    "], p=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732a5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "\n",
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, defaultpath='/home/beomgon/Dataset/new_patches/', transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.dir = defaultpath\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.iloc[idx, 4]\n",
    "#         print(pid)\n",
    "\n",
    "        image = cv2.imread(self.dir + path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image = (image.astype(np.float32)-128.)/128.\n",
    "        \n",
    "#         if image is uint8, normalization by 255 is done automatically by albumebtation(ToTensor method)\n",
    "        if self.transform:\n",
    "            timage = self.transform(image=image)\n",
    "            image = timage['image']\n",
    "        \n",
    "        image =  torch.tensor(image, dtype=torch.float32)/255.\n",
    "        #image = (torch.tensor(image, dtype=torch.float32)-128)/128\n",
    "        image = image.permute(2,0,1)\n",
    "            \n",
    "        label = self.df.iloc[idx, 5]\n",
    "        return image, label, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada50d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../dataframe/train_New_Stomach_df.csv')\n",
    "train_dataset = CDataset(train_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/', \n",
    "                        transform=train_transforms)\n",
    "\n",
    "val_df = pd.read_csv('../dataframe/val_New_Stomach_df.csv')\n",
    "val_dataset = CDataset(val_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/',\n",
    "                       transform=val_transforms)  \n",
    "\n",
    "test_df = pd.read_csv('../dataframe/test_New_Stomach_df.csv')\n",
    "test_dataset = CDataset(test_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/',\n",
    "                        transform=val_transforms)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aab4913-8558-4fb7-83e7-bde338b8c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_shuffled[:2000].label_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfca7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label, path = next(iter(train_dataset))\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6787059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dffcb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels, paths = next(iter(train_loader))\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfccf8f5-24fb-4986-9ad0-91ce95498912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f0d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "# from resnet import resnet18\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc = nn.Linear(2048, 3)\n",
    "torch.nn.init.normal_(model.fc.weight, std=0.01)\n",
    "torch.nn.init.constant_(model.fc.bias, 0.)\n",
    "default_state_dict = model.state_dict()\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.Adam(params, lr=0.01, weight_decay=args.weight_decay)\n",
    "optimizer = torch.optim.SGD(\n",
    "       params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = torch.optim.SGD(params, lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 15, 20, 25, 30], \n",
    "                                                    gamma=0.2)\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e0cf189-d9d0-4d14-bcb8-2071d3497b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21047c40-140f-4212-b841-7e9ac1bd7503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/593]\tTime  3.026 ( 3.026)\tData  2.134 ( 2.134)\tLoss 1.1234e+00 (1.1234e+00)\tAcc@1  39.06 ( 39.06)\n",
      "Test: [  0/203]\tTime  2.063 ( 2.063)\tLoss 1.5562e+00 (1.5562e+00)\tAcc@1  53.91 ( 53.91)\n",
      " * Acc@1 51.377\n",
      "Epoch: [1][  0/593]\tTime  2.320 ( 2.320)\tData  1.951 ( 1.951)\tLoss 7.4914e-01 (7.4914e-01)\tAcc@1  67.19 ( 67.19)\n",
      "Test: [  0/203]\tTime  2.028 ( 2.028)\tLoss 2.1521e+00 (2.1521e+00)\tAcc@1  43.75 ( 43.75)\n",
      " * Acc@1 50.256\n",
      "Epoch: [2][  0/593]\tTime  1.857 ( 1.857)\tData  1.476 ( 1.476)\tLoss 6.9498e-01 (6.9498e-01)\tAcc@1  71.88 ( 71.88)\n",
      "Test: [  0/203]\tTime  1.912 ( 1.912)\tLoss 1.5736e+00 (1.5736e+00)\tAcc@1  60.94 ( 60.94)\n",
      " * Acc@1 52.198\n",
      "Epoch: [3][  0/593]\tTime  2.007 ( 2.007)\tData  1.599 ( 1.599)\tLoss 6.2074e-01 (6.2074e-01)\tAcc@1  76.56 ( 76.56)\n",
      "Test: [  0/203]\tTime  1.835 ( 1.835)\tLoss 2.6247e+00 (2.6247e+00)\tAcc@1  55.47 ( 55.47)\n",
      " * Acc@1 58.411\n",
      "Epoch: [4][  0/593]\tTime  2.113 ( 2.113)\tData  1.730 ( 1.730)\tLoss 4.3328e-01 (4.3328e-01)\tAcc@1  84.38 ( 84.38)\n",
      "Test: [  0/203]\tTime  1.659 ( 1.659)\tLoss 4.6790e+00 (4.6790e+00)\tAcc@1  32.03 ( 32.03)\n",
      " * Acc@1 34.829\n",
      "Epoch: [5][  0/593]\tTime  2.243 ( 2.243)\tData  1.868 ( 1.868)\tLoss 6.5862e-01 (6.5862e-01)\tAcc@1  80.47 ( 80.47)\n",
      "Test: [  0/203]\tTime  2.306 ( 2.306)\tLoss 8.7456e-01 (8.7456e-01)\tAcc@1  72.66 ( 72.66)\n",
      " * Acc@1 71.419\n",
      "Epoch: [6][  0/593]\tTime  1.887 ( 1.887)\tData  1.509 ( 1.509)\tLoss 3.3832e-01 (3.3832e-01)\tAcc@1  87.50 ( 87.50)\n",
      "Test: [  0/203]\tTime  1.422 ( 1.422)\tLoss 7.4951e-01 (7.4951e-01)\tAcc@1  76.56 ( 76.56)\n",
      " * Acc@1 77.385\n",
      "Epoch: [7][  0/593]\tTime  2.253 ( 2.253)\tData  1.861 ( 1.861)\tLoss 4.0673e-01 (4.0673e-01)\tAcc@1  81.25 ( 81.25)\n",
      "Test: [  0/203]\tTime  2.116 ( 2.116)\tLoss 1.4329e+00 (1.4329e+00)\tAcc@1  55.47 ( 55.47)\n",
      " * Acc@1 54.466\n",
      "Epoch: [8][  0/593]\tTime  1.656 ( 1.656)\tData  1.261 ( 1.261)\tLoss 3.9162e-01 (3.9162e-01)\tAcc@1  83.59 ( 83.59)\n",
      "Test: [  0/203]\tTime  1.437 ( 1.437)\tLoss 6.6404e-01 (6.6404e-01)\tAcc@1  77.34 ( 77.34)\n",
      " * Acc@1 70.040\n",
      "Epoch: [9][  0/593]\tTime  1.718 ( 1.718)\tData  1.361 ( 1.361)\tLoss 2.8308e-01 (2.8308e-01)\tAcc@1  89.84 ( 89.84)\n",
      "Test: [  0/203]\tTime  2.166 ( 2.166)\tLoss 1.3824e+00 (1.3824e+00)\tAcc@1  67.19 ( 67.19)\n",
      " * Acc@1 63.206\n",
      "Epoch: [10][  0/593]\tTime  2.396 ( 2.396)\tData  1.999 ( 1.999)\tLoss 4.5152e-01 (4.5152e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Test: [  0/203]\tTime  1.487 ( 1.487)\tLoss 5.0297e-01 (5.0297e-01)\tAcc@1  81.25 ( 81.25)\n",
      " * Acc@1 82.924\n",
      "Epoch: [11][  0/593]\tTime  2.058 ( 2.058)\tData  1.700 ( 1.700)\tLoss 3.3665e-01 (3.3665e-01)\tAcc@1  83.59 ( 83.59)\n",
      "Test: [  0/203]\tTime  1.737 ( 1.737)\tLoss 6.5286e-01 (6.5286e-01)\tAcc@1  77.34 ( 77.34)\n",
      " * Acc@1 76.234\n",
      "Epoch: [12][  0/593]\tTime  2.453 ( 2.453)\tData  2.079 ( 2.079)\tLoss 1.5231e-01 (1.5231e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Test: [  0/203]\tTime  1.641 ( 1.641)\tLoss 6.0922e-01 (6.0922e-01)\tAcc@1  76.56 ( 76.56)\n",
      " * Acc@1 79.007\n",
      "Epoch: [13][  0/593]\tTime  2.265 ( 2.265)\tData  1.886 ( 1.886)\tLoss 2.0457e-01 (2.0457e-01)\tAcc@1  94.53 ( 94.53)\n",
      "Test: [  0/203]\tTime  2.212 ( 2.212)\tLoss 4.4192e-01 (4.4192e-01)\tAcc@1  86.72 ( 86.72)\n",
      " * Acc@1 84.854\n",
      "Epoch: [14][  0/593]\tTime  2.293 ( 2.293)\tData  1.913 ( 1.913)\tLoss 3.3413e-01 (3.3413e-01)\tAcc@1  86.72 ( 86.72)\n",
      "Test: [  0/203]\tTime  2.088 ( 2.088)\tLoss 4.5169e-01 (4.5169e-01)\tAcc@1  83.59 ( 83.59)\n",
      " * Acc@1 81.260\n",
      "Epoch: [15][  0/593]\tTime  1.977 ( 1.977)\tData  1.609 ( 1.609)\tLoss 2.3280e-01 (2.3280e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Test: [  0/203]\tTime  1.794 ( 1.794)\tLoss 5.8919e-01 (5.8919e-01)\tAcc@1  82.03 ( 82.03)\n",
      " * Acc@1 76.049\n",
      "Epoch: [16][  0/593]\tTime  1.903 ( 1.903)\tData  1.499 ( 1.499)\tLoss 2.5090e-01 (2.5090e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Test: [  0/203]\tTime  1.792 ( 1.792)\tLoss 7.8350e-01 (7.8350e-01)\tAcc@1  78.91 ( 78.91)\n",
      " * Acc@1 73.541\n",
      "Epoch: [17][  0/593]\tTime  2.022 ( 2.022)\tData  1.646 ( 1.646)\tLoss 2.0657e-01 (2.0657e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Test: [  0/203]\tTime  1.983 ( 1.983)\tLoss 3.2670e-01 (3.2670e-01)\tAcc@1  82.81 ( 82.81)\n",
      " * Acc@1 82.412\n",
      "Epoch: [18][  0/593]\tTime  2.314 ( 2.314)\tData  1.931 ( 1.931)\tLoss 2.6993e-01 (2.6993e-01)\tAcc@1  92.97 ( 92.97)\n",
      "Test: [  0/203]\tTime  2.277 ( 2.277)\tLoss 5.4453e-01 (5.4453e-01)\tAcc@1  78.91 ( 78.91)\n",
      " * Acc@1 82.204\n",
      "Epoch: [19][  0/593]\tTime  1.595 ( 1.595)\tData  1.206 ( 1.206)\tLoss 2.3607e-01 (2.3607e-01)\tAcc@1  91.41 ( 91.41)\n",
      "Test: [  0/203]\tTime  1.454 ( 1.454)\tLoss 9.2306e-01 (9.2306e-01)\tAcc@1  72.66 ( 72.66)\n",
      " * Acc@1 71.365\n",
      "Epoch: [20][  0/593]\tTime  2.053 ( 2.053)\tData  1.679 ( 1.679)\tLoss 2.4734e-01 (2.4734e-01)\tAcc@1  89.84 ( 89.84)\n",
      "Test: [  0/203]\tTime  1.711 ( 1.711)\tLoss 5.6648e-01 (5.6648e-01)\tAcc@1  83.59 ( 83.59)\n",
      " * Acc@1 82.897\n",
      "Epoch: [21][  0/593]\tTime  2.022 ( 2.022)\tData  1.645 ( 1.645)\tLoss 1.8021e-01 (1.8021e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  1.591 ( 1.591)\tLoss 4.2131e-01 (4.2131e-01)\tAcc@1  82.81 ( 82.81)\n",
      " * Acc@1 83.510\n",
      "Epoch: [22][  0/593]\tTime  1.981 ( 1.981)\tData  1.608 ( 1.608)\tLoss 2.4380e-01 (2.4380e-01)\tAcc@1  89.84 ( 89.84)\n",
      "Test: [  0/203]\tTime  1.748 ( 1.748)\tLoss 3.3872e-01 (3.3872e-01)\tAcc@1  85.94 ( 85.94)\n",
      " * Acc@1 82.955\n",
      "Epoch: [23][  0/593]\tTime  1.591 ( 1.591)\tData  1.177 ( 1.177)\tLoss 1.8664e-01 (1.8664e-01)\tAcc@1  94.53 ( 94.53)\n",
      "Test: [  0/203]\tTime  1.726 ( 1.726)\tLoss 3.9594e-01 (3.9594e-01)\tAcc@1  85.16 ( 85.16)\n",
      " * Acc@1 86.911\n",
      "Epoch: [24][  0/593]\tTime  1.718 ( 1.718)\tData  1.316 ( 1.316)\tLoss 1.6672e-01 (1.6672e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Test: [  0/203]\tTime  1.682 ( 1.682)\tLoss 4.4242e-01 (4.4242e-01)\tAcc@1  85.94 ( 85.94)\n",
      " * Acc@1 85.494\n",
      "Epoch: [25][  0/593]\tTime  1.851 ( 1.851)\tData  1.442 ( 1.442)\tLoss 8.9161e-02 (8.9161e-02)\tAcc@1  97.66 ( 97.66)\n",
      "Test: [  0/203]\tTime  1.931 ( 1.931)\tLoss 3.1336e-01 (3.1336e-01)\tAcc@1  86.72 ( 86.72)\n",
      " * Acc@1 86.842\n",
      "Epoch: [26][  0/593]\tTime  1.832 ( 1.832)\tData  1.443 ( 1.443)\tLoss 2.2866e-01 (2.2866e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  1.620 ( 1.620)\tLoss 3.7264e-01 (3.7264e-01)\tAcc@1  85.16 ( 85.16)\n",
      " * Acc@1 86.499\n",
      "Epoch: [27][  0/593]\tTime  1.841 ( 1.841)\tData  1.451 ( 1.451)\tLoss 9.0337e-02 (9.0337e-02)\tAcc@1  98.44 ( 98.44)\n",
      "Test: [  0/203]\tTime  1.399 ( 1.399)\tLoss 5.6891e-01 (5.6891e-01)\tAcc@1  83.59 ( 83.59)\n",
      " * Acc@1 86.079\n",
      "Epoch: [28][  0/593]\tTime  2.273 ( 2.273)\tData  1.890 ( 1.890)\tLoss 2.3764e-01 (2.3764e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Test: [  0/203]\tTime  1.753 ( 1.753)\tLoss 5.0781e-01 (5.0781e-01)\tAcc@1  84.38 ( 84.38)\n",
      " * Acc@1 85.070\n",
      "Epoch: [29][  0/593]\tTime  2.351 ( 2.351)\tData  1.972 ( 1.972)\tLoss 2.0808e-01 (2.0808e-01)\tAcc@1  91.41 ( 91.41)\n",
      "Test: [  0/203]\tTime  1.376 ( 1.376)\tLoss 4.2402e-01 (4.2402e-01)\tAcc@1  86.72 ( 86.72)\n",
      " * Acc@1 85.983\n",
      "Epoch: [30][  0/593]\tTime  2.293 ( 2.293)\tData  1.930 ( 1.930)\tLoss 1.4856e-01 (1.4856e-01)\tAcc@1  92.97 ( 92.97)\n",
      "Test: [  0/203]\tTime  1.772 ( 1.772)\tLoss 2.8423e-01 (2.8423e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 87.616\n",
      "Epoch: [31][  0/593]\tTime  1.866 ( 1.866)\tData  1.494 ( 1.494)\tLoss 1.0620e-01 (1.0620e-01)\tAcc@1  96.09 ( 96.09)\n",
      "Test: [  0/203]\tTime  1.431 ( 1.431)\tLoss 3.4835e-01 (3.4835e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 86.930\n",
      "Epoch: [32][  0/593]\tTime  2.433 ( 2.433)\tData  2.048 ( 2.048)\tLoss 6.3891e-02 (6.3891e-02)\tAcc@1  98.44 ( 98.44)\n",
      "Test: [  0/203]\tTime  1.712 ( 1.712)\tLoss 2.8667e-01 (2.8667e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 87.370\n",
      "Epoch: [33][  0/593]\tTime  2.615 ( 2.615)\tData  2.215 ( 2.215)\tLoss 1.8736e-01 (1.8736e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  1.798 ( 1.798)\tLoss 4.1305e-01 (4.1305e-01)\tAcc@1  82.03 ( 82.03)\n",
      " * Acc@1 87.624\n",
      "Epoch: [34][  0/593]\tTime  2.064 ( 2.064)\tData  1.679 ( 1.679)\tLoss 1.4098e-01 (1.4098e-01)\tAcc@1  91.41 ( 91.41)\n",
      "Test: [  0/203]\tTime  2.084 ( 2.084)\tLoss 2.5249e-01 (2.5249e-01)\tAcc@1  89.84 ( 89.84)\n",
      " * Acc@1 87.574\n",
      "Epoch: [35][  0/593]\tTime  2.553 ( 2.553)\tData  2.159 ( 2.159)\tLoss 1.0864e-01 (1.0864e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Test: [  0/203]\tTime  2.212 ( 2.212)\tLoss 2.6116e-01 (2.6116e-01)\tAcc@1  85.16 ( 85.16)\n",
      " * Acc@1 87.192\n",
      "Epoch: [36][  0/593]\tTime  2.322 ( 2.322)\tData  1.961 ( 1.961)\tLoss 1.7248e-01 (1.7248e-01)\tAcc@1  92.97 ( 92.97)\n",
      "Test: [  0/203]\tTime  1.942 ( 1.942)\tLoss 2.7911e-01 (2.7911e-01)\tAcc@1  87.50 ( 87.50)\n",
      " * Acc@1 87.481\n",
      "Epoch: [37][  0/593]\tTime  2.402 ( 2.402)\tData  2.019 ( 2.019)\tLoss 1.3479e-01 (1.3479e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Test: [  0/203]\tTime  1.709 ( 1.709)\tLoss 4.3984e-01 (4.3984e-01)\tAcc@1  85.94 ( 85.94)\n",
      " * Acc@1 85.987\n",
      "Epoch: [38][  0/593]\tTime  1.748 ( 1.748)\tData  1.355 ( 1.355)\tLoss 1.5089e-01 (1.5089e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  1.722 ( 1.722)\tLoss 3.9765e-01 (3.9765e-01)\tAcc@1  84.38 ( 84.38)\n",
      " * Acc@1 87.620\n",
      "Epoch: [39][  0/593]\tTime  1.813 ( 1.813)\tData  1.390 ( 1.390)\tLoss 1.3474e-01 (1.3474e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Test: [  0/203]\tTime  2.124 ( 2.124)\tLoss 3.3931e-01 (3.3931e-01)\tAcc@1  86.72 ( 86.72)\n",
      " * Acc@1 86.195\n",
      "Epoch: [40][  0/593]\tTime  2.257 ( 2.257)\tData  1.868 ( 1.868)\tLoss 1.6040e-01 (1.6040e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  1.826 ( 1.826)\tLoss 4.1426e-01 (4.1426e-01)\tAcc@1  82.81 ( 82.81)\n",
      " * Acc@1 87.566\n",
      "Epoch: [41][  0/593]\tTime  2.031 ( 2.031)\tData  1.653 ( 1.653)\tLoss 1.6455e-01 (1.6455e-01)\tAcc@1  94.53 ( 94.53)\n",
      "Test: [  0/203]\tTime  2.152 ( 2.152)\tLoss 4.1427e-01 (4.1427e-01)\tAcc@1  85.16 ( 85.16)\n",
      " * Acc@1 87.462\n",
      "Epoch: [42][  0/593]\tTime  2.308 ( 2.308)\tData  1.912 ( 1.912)\tLoss 2.2390e-01 (2.2390e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Test: [  0/203]\tTime  1.768 ( 1.768)\tLoss 4.1095e-01 (4.1095e-01)\tAcc@1  87.50 ( 87.50)\n",
      " * Acc@1 87.782\n",
      "Epoch: [43][  0/593]\tTime  1.880 ( 1.880)\tData  1.490 ( 1.490)\tLoss 2.0434e-01 (2.0434e-01)\tAcc@1  92.97 ( 92.97)\n",
      "Test: [  0/203]\tTime  1.757 ( 1.757)\tLoss 4.0573e-01 (4.0573e-01)\tAcc@1  87.50 ( 87.50)\n",
      " * Acc@1 86.306\n",
      "Epoch: [44][  0/593]\tTime  1.632 ( 1.632)\tData  1.240 ( 1.240)\tLoss 1.7234e-01 (1.7234e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Test: [  0/203]\tTime  2.060 ( 2.060)\tLoss 3.9136e-01 (3.9136e-01)\tAcc@1  85.16 ( 85.16)\n",
      " * Acc@1 86.591\n",
      "Epoch: [45][  0/593]\tTime  2.323 ( 2.323)\tData  1.943 ( 1.943)\tLoss 1.6427e-01 (1.6427e-01)\tAcc@1  94.53 ( 94.53)\n",
      "Test: [  0/203]\tTime  1.719 ( 1.719)\tLoss 3.2905e-01 (3.2905e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 87.308\n",
      "Epoch: [46][  0/593]\tTime  2.352 ( 2.352)\tData  1.952 ( 1.952)\tLoss 9.5440e-02 (9.5440e-02)\tAcc@1  96.88 ( 96.88)\n",
      "Test: [  0/203]\tTime  1.989 ( 1.989)\tLoss 3.2589e-01 (3.2589e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 87.242\n",
      "Epoch: [47][  0/593]\tTime  1.814 ( 1.814)\tData  1.451 ( 1.451)\tLoss 1.3003e-01 (1.3003e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Test: [  0/203]\tTime  2.006 ( 2.006)\tLoss 3.3912e-01 (3.3912e-01)\tAcc@1  88.28 ( 88.28)\n",
      " * Acc@1 87.678\n",
      "Epoch: [48][  0/593]\tTime  2.007 ( 2.007)\tData  1.644 ( 1.644)\tLoss 1.3012e-01 (1.3012e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Test: [  0/203]\tTime  1.802 ( 1.802)\tLoss 2.7478e-01 (2.7478e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 87.604\n",
      "Epoch: [49][  0/593]\tTime  1.572 ( 1.572)\tData  1.167 ( 1.167)\tLoss 1.6157e-01 (1.6157e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  1.675 ( 1.675)\tLoss 4.2786e-01 (4.2786e-01)\tAcc@1  83.59 ( 83.59)\n",
      " * Acc@1 85.906\n",
      "Test: [  0/119]\tTime  2.026 ( 2.026)\tLoss 4.1417e-01 (4.1417e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 89.688\n",
      "************* test number 0 ratio 0.8 acc89.68846893310547 *************\n",
      "Epoch: [0][  0/593]\tTime  2.394 ( 2.394)\tData  2.073 ( 2.073)\tLoss 1.1317e+00 (1.1317e+00)\tAcc@1  31.25 ( 31.25)\n",
      "Test: [  0/203]\tTime  2.112 ( 2.112)\tLoss 8.4694e-01 (8.4694e-01)\tAcc@1  61.72 ( 61.72)\n",
      " * Acc@1 59.443\n",
      "Epoch: [1][  0/593]\tTime  2.213 ( 2.213)\tData  1.812 ( 1.812)\tLoss 7.4181e-01 (7.4181e-01)\tAcc@1  67.19 ( 67.19)\n",
      "Test: [  0/203]\tTime  2.372 ( 2.372)\tLoss 1.1516e+00 (1.1516e+00)\tAcc@1  59.38 ( 59.38)\n",
      " * Acc@1 62.032\n",
      "Epoch: [2][  0/593]\tTime  2.293 ( 2.293)\tData  1.929 ( 1.929)\tLoss 6.1374e-01 (6.1374e-01)\tAcc@1  78.12 ( 78.12)\n",
      "Test: [  0/203]\tTime  1.801 ( 1.801)\tLoss 8.0618e-01 (8.0618e-01)\tAcc@1  67.97 ( 67.97)\n",
      " * Acc@1 68.349\n",
      "Epoch: [3][  0/593]\tTime  1.931 ( 1.931)\tData  1.556 ( 1.556)\tLoss 6.8935e-01 (6.8935e-01)\tAcc@1  72.66 ( 72.66)\n",
      "Test: [  0/203]\tTime  1.932 ( 1.932)\tLoss 1.8997e+00 (1.8997e+00)\tAcc@1  51.56 ( 51.56)\n",
      " * Acc@1 47.271\n",
      "Epoch: [4][  0/593]\tTime  1.945 ( 1.945)\tData  1.572 ( 1.572)\tLoss 4.0777e-01 (4.0777e-01)\tAcc@1  81.25 ( 81.25)\n",
      "Test: [  0/203]\tTime  1.747 ( 1.747)\tLoss 7.1048e-01 (7.1048e-01)\tAcc@1  72.66 ( 72.66)\n",
      " * Acc@1 72.478\n",
      "Epoch: [5][  0/593]\tTime  2.180 ( 2.180)\tData  1.767 ( 1.767)\tLoss 4.3357e-01 (4.3357e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Test: [  0/203]\tTime  2.342 ( 2.342)\tLoss 6.5021e-01 (6.5021e-01)\tAcc@1  80.47 ( 80.47)\n",
      " * Acc@1 75.340\n",
      "Epoch: [6][  0/593]\tTime  2.190 ( 2.190)\tData  1.782 ( 1.782)\tLoss 2.8421e-01 (2.8421e-01)\tAcc@1  91.41 ( 91.41)\n",
      "Test: [  0/203]\tTime  1.799 ( 1.799)\tLoss 1.5988e+01 (1.5988e+01)\tAcc@1  40.62 ( 40.62)\n",
      " * Acc@1 40.711\n",
      "Epoch: [7][  0/593]\tTime  2.302 ( 2.302)\tData  1.918 ( 1.918)\tLoss 2.7658e-01 (2.7658e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Test: [  0/203]\tTime  1.931 ( 1.931)\tLoss 1.5741e+00 (1.5741e+00)\tAcc@1  53.91 ( 53.91)\n",
      " * Acc@1 50.730\n",
      "Epoch: [8][  0/593]\tTime  1.823 ( 1.823)\tData  1.436 ( 1.436)\tLoss 3.4673e-01 (3.4673e-01)\tAcc@1  85.94 ( 85.94)\n",
      "Test: [  0/203]\tTime  1.803 ( 1.803)\tLoss 5.6814e-01 (5.6814e-01)\tAcc@1  80.47 ( 80.47)\n",
      " * Acc@1 79.562\n",
      "Epoch: [9][  0/593]\tTime  2.462 ( 2.462)\tData  2.101 ( 2.101)\tLoss 2.8448e-01 (2.8448e-01)\tAcc@1  89.84 ( 89.84)\n",
      "Test: [  0/203]\tTime  1.803 ( 1.803)\tLoss 6.2631e-01 (6.2631e-01)\tAcc@1  81.25 ( 81.25)\n",
      " * Acc@1 77.304\n",
      "Epoch: [10][  0/593]\tTime  2.712 ( 2.712)\tData  2.329 ( 2.329)\tLoss 2.5025e-01 (2.5025e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Test: [  0/203]\tTime  1.562 ( 1.562)\tLoss 3.8871e-01 (3.8871e-01)\tAcc@1  85.16 ( 85.16)\n",
      " * Acc@1 82.813\n",
      "Epoch: [11][  0/593]\tTime  2.677 ( 2.677)\tData  2.293 ( 2.293)\tLoss 1.7916e-01 (1.7916e-01)\tAcc@1  94.53 ( 94.53)\n",
      "Test: [  0/203]\tTime  1.609 ( 1.609)\tLoss 4.8896e-01 (4.8896e-01)\tAcc@1  76.56 ( 76.56)\n",
      " * Acc@1 75.471\n",
      "Epoch: [12][  0/593]\tTime  1.971 ( 1.971)\tData  1.568 ( 1.568)\tLoss 1.7746e-01 (1.7746e-01)\tAcc@1  91.41 ( 91.41)\n",
      "Test: [  0/203]\tTime  1.716 ( 1.716)\tLoss 8.6972e-01 (8.6972e-01)\tAcc@1  72.66 ( 72.66)\n",
      " * Acc@1 78.572\n",
      "Epoch: [13][  0/593]\tTime  2.037 ( 2.037)\tData  1.666 ( 1.666)\tLoss 2.4080e-01 (2.4080e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Test: [  0/203]\tTime  2.008 ( 2.008)\tLoss 1.3205e+01 (1.3205e+01)\tAcc@1  65.62 ( 65.62)\n",
      " * Acc@1 63.626\n",
      "Epoch: [14][  0/593]\tTime  2.243 ( 2.243)\tData  1.827 ( 1.827)\tLoss 1.3996e-01 (1.3996e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  2.178 ( 2.178)\tLoss 4.7892e-01 (4.7892e-01)\tAcc@1  83.59 ( 83.59)\n",
      " * Acc@1 78.653\n",
      "Epoch: [15][  0/593]\tTime  1.694 ( 1.694)\tData  1.309 ( 1.309)\tLoss 1.1568e-01 (1.1568e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Test: [  0/203]\tTime  1.787 ( 1.787)\tLoss 6.2674e-01 (6.2674e-01)\tAcc@1  74.22 ( 74.22)\n",
      " * Acc@1 78.264\n",
      "Epoch: [16][  0/593]\tTime  2.764 ( 2.764)\tData  2.382 ( 2.382)\tLoss 2.0420e-01 (2.0420e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  2.063 ( 2.063)\tLoss 7.6857e-01 (7.6857e-01)\tAcc@1  73.44 ( 73.44)\n",
      " * Acc@1 82.921\n",
      "Epoch: [17][  0/593]\tTime  2.000 ( 2.000)\tData  1.610 ( 1.610)\tLoss 2.8102e-01 (2.8102e-01)\tAcc@1  89.84 ( 89.84)\n",
      "Test: [  0/203]\tTime  2.219 ( 2.219)\tLoss 4.1115e-01 (4.1115e-01)\tAcc@1  86.72 ( 86.72)\n",
      " * Acc@1 82.489\n",
      "Epoch: [18][  0/593]\tTime  2.282 ( 2.282)\tData  1.891 ( 1.891)\tLoss 1.3060e-01 (1.3060e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  1.827 ( 1.827)\tLoss 2.2486e+01 (2.2486e+01)\tAcc@1  58.59 ( 58.59)\n",
      " * Acc@1 64.843\n",
      "Epoch: [19][  0/593]\tTime  2.431 ( 2.431)\tData  2.051 ( 2.051)\tLoss 2.4613e-01 (2.4613e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Test: [  0/203]\tTime  1.989 ( 1.989)\tLoss 1.1390e+01 (1.1390e+01)\tAcc@1  57.81 ( 57.81)\n",
      " * Acc@1 49.798\n",
      "Epoch: [20][  0/593]\tTime  1.981 ( 1.981)\tData  1.599 ( 1.599)\tLoss 1.8596e-01 (1.8596e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Test: [  0/203]\tTime  2.224 ( 2.224)\tLoss 3.4723e-01 (3.4723e-01)\tAcc@1  86.72 ( 86.72)\n",
      " * Acc@1 86.464\n",
      "Epoch: [21][  0/593]\tTime  1.725 ( 1.725)\tData  1.358 ( 1.358)\tLoss 1.3134e-01 (1.3134e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  2.260 ( 2.260)\tLoss 4.0737e-01 (4.0737e-01)\tAcc@1  85.16 ( 85.16)\n",
      " * Acc@1 84.689\n",
      "Epoch: [22][  0/593]\tTime  1.715 ( 1.715)\tData  1.353 ( 1.353)\tLoss 1.6650e-01 (1.6650e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Test: [  0/203]\tTime  2.264 ( 2.264)\tLoss 5.2956e-01 (5.2956e-01)\tAcc@1  80.47 ( 80.47)\n",
      " * Acc@1 85.309\n",
      "Epoch: [23][  0/593]\tTime  2.370 ( 2.370)\tData  1.993 ( 1.993)\tLoss 1.3970e-01 (1.3970e-01)\tAcc@1  94.53 ( 94.53)\n",
      "Test: [  0/203]\tTime  2.195 ( 2.195)\tLoss 3.0382e-01 (3.0382e-01)\tAcc@1  91.41 ( 91.41)\n",
      " * Acc@1 87.751\n",
      "Epoch: [24][  0/593]\tTime  1.810 ( 1.810)\tData  1.438 ( 1.438)\tLoss 7.7997e-02 (7.7997e-02)\tAcc@1  99.22 ( 99.22)\n",
      "Test: [  0/203]\tTime  2.237 ( 2.237)\tLoss 2.1591e+00 (2.1591e+00)\tAcc@1  76.56 ( 76.56)\n",
      " * Acc@1 77.520\n",
      "Epoch: [25][  0/593]\tTime  2.382 ( 2.382)\tData  2.006 ( 2.006)\tLoss 7.7261e-02 (7.7261e-02)\tAcc@1  96.88 ( 96.88)\n",
      "Test: [  0/203]\tTime  2.207 ( 2.207)\tLoss 1.9089e-01 (1.9089e-01)\tAcc@1  92.19 ( 92.19)\n",
      " * Acc@1 88.340\n",
      "Epoch: [26][  0/593]\tTime  2.241 ( 2.241)\tData  1.848 ( 1.848)\tLoss 1.7414e-01 (1.7414e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  1.474 ( 1.474)\tLoss 2.1533e+00 (2.1533e+00)\tAcc@1  71.88 ( 71.88)\n",
      " * Acc@1 77.955\n",
      "Epoch: [27][  0/593]\tTime  1.743 ( 1.743)\tData  1.335 ( 1.335)\tLoss 1.0259e-01 (1.0259e-01)\tAcc@1  96.88 ( 96.88)\n",
      "Test: [  0/203]\tTime  1.522 ( 1.522)\tLoss 6.8192e-01 (6.8192e-01)\tAcc@1  80.47 ( 80.47)\n",
      " * Acc@1 84.184\n",
      "Epoch: [28][  0/593]\tTime  1.986 ( 1.986)\tData  1.588 ( 1.588)\tLoss 1.2025e-01 (1.2025e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Test: [  0/203]\tTime  1.796 ( 1.796)\tLoss 7.9505e-01 (7.9505e-01)\tAcc@1  82.81 ( 82.81)\n",
      " * Acc@1 82.585\n",
      "Epoch: [29][  0/593]\tTime  2.495 ( 2.495)\tData  2.091 ( 2.091)\tLoss 1.1885e-01 (1.1885e-01)\tAcc@1  95.31 ( 95.31)\n",
      "Test: [  0/203]\tTime  1.530 ( 1.530)\tLoss 3.5076e-01 (3.5076e-01)\tAcc@1  81.25 ( 81.25)\n",
      " * Acc@1 86.950\n",
      "Epoch: [30][  0/593]\tTime  2.095 ( 2.095)\tData  1.712 ( 1.712)\tLoss 1.1009e-01 (1.1009e-01)\tAcc@1  94.53 ( 94.53)\n",
      "Test: [  0/203]\tTime  1.784 ( 1.784)\tLoss 3.7931e-01 (3.7931e-01)\tAcc@1  88.28 ( 88.28)\n",
      " * Acc@1 84.330\n",
      "Epoch: [31][  0/593]\tTime  1.665 ( 1.665)\tData  1.275 ( 1.275)\tLoss 1.6125e-01 (1.6125e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/203]\tTime  2.542 ( 2.542)\tLoss 3.8452e-01 (3.8452e-01)\tAcc@1  85.16 ( 85.16)\n",
      " * Acc@1 87.770\n",
      "Epoch: [32][  0/593]\tTime  1.948 ( 1.948)\tData  1.552 ( 1.552)\tLoss 1.2022e-01 (1.2022e-01)\tAcc@1  94.53 ( 94.53)\n",
      "Test: [  0/203]\tTime  2.281 ( 2.281)\tLoss 6.3493e-01 (6.3493e-01)\tAcc@1  82.03 ( 82.03)\n",
      " * Acc@1 84.612\n",
      "Epoch: [33][  0/593]\tTime  2.146 ( 2.146)\tData  1.767 ( 1.767)\tLoss 1.7490e-01 (1.7490e-01)\tAcc@1  92.97 ( 92.97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4fd1e83430>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29940/184744803.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#         print('lr', optimizer.param_groups[0]['lr'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/seegene/working8/../main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, args)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# measure accuracy and record loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0macc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mtop1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ratio = [.8, .8, .8]\n",
    "acc_list = []\n",
    "test_acc = []\n",
    "\n",
    "for num in range(len(ratio)) :\n",
    "    args.saved_dir = '../trained_models/resnet8/stomach1_4' + str(num) + '/checkpoint.pt'\n",
    "    path = Path(args.saved_dir.split('checkpoint')[0])\n",
    "    path.mkdir(parents=True, exist_ok=True)  \n",
    "    \n",
    "    model = models.resnet50(pretrained=False)\n",
    "    model.fc = nn.Linear(2048, 3)\n",
    "    torch.nn.init.normal_(model.fc.weight, std=0.01)\n",
    "    torch.nn.init.constant_(model.fc.bias, 0.)    \n",
    "    # model.load_state_dict(default_state_dict)\n",
    "    model.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "#     optimizer = torch.optim.Adam(params, lr=0.01, weight_decay=args.weight_decay)\n",
    "    optimizer = torch.optim.SGD(\n",
    "           params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 20, 30, 40], \n",
    "                                                        gamma=0.2)\n",
    "    # criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_acc1 = 0\n",
    "    acc1 = 0\n",
    "    train_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "#         print('lr', optimizer.param_groups[0]['lr'])\n",
    "        losses = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "        scheduler.step()\n",
    "\n",
    "        # evaluate after every epoch\n",
    "        acc1 = validate(val_loader, model, criterion, args)   \n",
    "        val_acc.append(acc1.item())\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1) \n",
    "\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'scheduler' : scheduler.state_dict(),\n",
    "        }, is_best, filename=args.saved_dir)   \n",
    "        \n",
    "    checkpoint = torch.load(args.saved_dir)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    acc1 = validate(test_loader, model, criterion, args)    \n",
    "    print('************* test number {} ratio {} acc{} *************'.format(num, ratio[num], acc1))    \n",
    "    acc_list.append(val_acc)    \n",
    "    test_acc.append(acc1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc41c0-29ea-4aea-aeea-07a3fc813ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(args.epochs)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.plot(epochs, acc_list[0], linestyle='--')\n",
    "plt.plot(epochs, acc_list[1])\n",
    "plt.plot(epochs, acc_list[2])\n",
    "# plt.plot(epochs, acc_list[3])\n",
    "plt.legend(['.4', '.4', '.4' ])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('val acc')\n",
    "plt.title('val acc with stain augment using resnet18 for stomach')\n",
    "# plt.axis([10, 30, 88, 94])\n",
    "plt.show()\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451bd47-e60e-4ae6-8eed-f8111f3c89e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
