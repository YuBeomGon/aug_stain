{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e4aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataset import val_transforms, CDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f1ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch_size\": 256, \n",
    "                          \"epochs\": 30, \n",
    "                          \"data\": 0, \n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':0,\n",
    "                          'workers':16,\n",
    "                         'print_freq':2000,\n",
    "                         'saved_dir':'../trained_models/checkpoint.pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f5ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make saved dir\n",
    "from pathlib import Path\n",
    "path = Path(args.saved_dir.split('checkpoint')[0])\n",
    "path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d1b194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print(ngpus_per_node)\n",
    "GPU_NUM = args.gpu # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c55e114-1622-42c4-9ce1-e1835910c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from augment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e52944",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=.8),\n",
    "        A.VerticalFlip(p=.8),\n",
    "        A.RandomRotate90(p=.8)]\n",
    "    ),\n",
    "    # HEColorAugment(sigma1=.4, sigma2=5., mat=None, p=0.9),\n",
    "], p=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732a5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "\n",
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, defaultpath='/home/beomgon/Dataset/new_patches/', transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.dir = defaultpath\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.iloc[idx, 4]\n",
    "#         print(pid)\n",
    "\n",
    "        image = cv2.imread(self.dir + path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image = (image.astype(np.float32)-128.)/128.\n",
    "        \n",
    "#         if image is uint8, normalization by 255 is done automatically by albumebtation(ToTensor method)\n",
    "        if self.transform:\n",
    "            timage = self.transform(image=image)\n",
    "            image = timage['image']\n",
    "        \n",
    "        image =  torch.tensor(image, dtype=torch.float32)/255.\n",
    "        #image = (torch.tensor(image, dtype=torch.float32)-128)/128\n",
    "        image = image.permute(2,0,1)\n",
    "            \n",
    "        label = self.df.iloc[idx, 5]\n",
    "        return image, label, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada50d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../dataframe/train_New_Stomach_df.csv')\n",
    "train_dataset = CDataset(train_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/', \n",
    "                         transform=train_transforms)\n",
    "\n",
    "val_df = pd.read_csv('../dataframe/val_New_Stomach_df.csv')\n",
    "val_dataset = CDataset(val_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/',\n",
    "                       transform=val_transforms)  \n",
    "\n",
    "test_df = pd.read_csv('../dataframe/test_New_Stomach_df.csv')\n",
    "test_dataset = CDataset(test_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/',\n",
    "                        transform=val_transforms)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfca7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label, path = next(iter(train_dataset))\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6787059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dffcb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels, paths = next(iter(train_loader))\n",
    "# images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfccf8f5-24fb-4986-9ad0-91ce95498912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.fc = nn.Linear(64, 3)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3f0d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision.models as models\n",
    "# from resnet import resnet18\n",
    "# model = resnet18(pretrained=False)\n",
    "model = Net()\n",
    "model.fc = nn.Linear(64, 3)\n",
    "torch.nn.init.normal_(model.fc.weight, std=0.01)\n",
    "torch.nn.init.constant_(model.fc.bias, 0.)\n",
    "default_state_dict = model.state_dict()\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.Adam(params, lr=0.01, weight_decay=args.weight_decay)\n",
    "optimizer = torch.optim.SGD(\n",
    "       params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "# optimizer = torch.optim.SGD(params, lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 15, 20, 25, 30], \n",
    "                                                    gamma=0.2)\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e0cf189-d9d0-4d14-bcb8-2071d3497b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21047c40-140f-4212-b841-7e9ac1bd7503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/297]\tTime  3.165 ( 3.165)\tData  2.278 ( 2.278)\tLoss 1.1003e+00 (1.1003e+00)\tAcc@1  30.08 ( 30.08)\n",
      "Test: [  0/102]\tTime  2.713 ( 2.713)\tLoss 1.0498e+00 (1.0498e+00)\tAcc@1  57.42 ( 57.42)\n",
      " * Acc@1 58.268\n",
      "Epoch: [1][  0/297]\tTime  2.067 ( 2.067)\tData  1.872 ( 1.872)\tLoss 5.4952e-01 (5.4952e-01)\tAcc@1  77.34 ( 77.34)\n",
      "Test: [  0/102]\tTime  2.243 ( 2.243)\tLoss 2.7443e+00 (2.7443e+00)\tAcc@1  43.75 ( 43.75)\n",
      " * Acc@1 46.181\n",
      "Epoch: [2][  0/297]\tTime  2.886 ( 2.886)\tData  2.724 ( 2.724)\tLoss 7.0619e-01 (7.0619e-01)\tAcc@1  74.22 ( 74.22)\n",
      "Test: [  0/102]\tTime  2.686 ( 2.686)\tLoss 5.2947e+00 (5.2947e+00)\tAcc@1  55.47 ( 55.47)\n",
      " * Acc@1 52.679\n",
      "Epoch: [3][  0/297]\tTime  1.855 ( 1.855)\tData  1.670 ( 1.670)\tLoss 5.3223e-01 (5.3223e-01)\tAcc@1  81.25 ( 81.25)\n",
      "Test: [  0/102]\tTime  2.408 ( 2.408)\tLoss 1.1101e+00 (1.1101e+00)\tAcc@1  64.06 ( 64.06)\n",
      " * Acc@1 60.075\n",
      "Epoch: [4][  0/297]\tTime  2.594 ( 2.594)\tData  2.451 ( 2.451)\tLoss 3.2734e-01 (3.2734e-01)\tAcc@1  85.55 ( 85.55)\n",
      "Test: [  0/102]\tTime  3.067 ( 3.067)\tLoss 2.8291e+00 (2.8291e+00)\tAcc@1  45.70 ( 45.70)\n",
      " * Acc@1 45.441\n",
      "Epoch: [5][  0/297]\tTime  2.351 ( 2.351)\tData  2.163 ( 2.163)\tLoss 3.3526e-01 (3.3526e-01)\tAcc@1  87.50 ( 87.50)\n",
      "Test: [  0/102]\tTime  2.622 ( 2.622)\tLoss 1.8109e+00 (1.8109e+00)\tAcc@1  51.17 ( 51.17)\n",
      " * Acc@1 51.046\n",
      "Epoch: [6][  0/297]\tTime  2.600 ( 2.600)\tData  2.421 ( 2.421)\tLoss 3.4868e-01 (3.4868e-01)\tAcc@1  83.59 ( 83.59)\n",
      "Test: [  0/102]\tTime  3.019 ( 3.019)\tLoss 5.5986e-01 (5.5986e-01)\tAcc@1  78.91 ( 78.91)\n",
      " * Acc@1 81.064\n",
      "Epoch: [7][  0/297]\tTime  2.331 ( 2.331)\tData  2.133 ( 2.133)\tLoss 3.1790e-01 (3.1790e-01)\tAcc@1  88.67 ( 88.67)\n",
      "Test: [  0/102]\tTime  2.416 ( 2.416)\tLoss 2.4495e+01 (2.4495e+01)\tAcc@1  37.89 ( 37.89)\n",
      " * Acc@1 36.239\n",
      "Epoch: [8][  0/297]\tTime  2.242 ( 2.242)\tData  2.022 ( 2.022)\tLoss 2.3056e-01 (2.3056e-01)\tAcc@1  91.41 ( 91.41)\n",
      "Test: [  0/102]\tTime  1.893 ( 1.893)\tLoss 2.0589e+00 (2.0589e+00)\tAcc@1  50.78 ( 50.78)\n",
      " * Acc@1 53.384\n",
      "Epoch: [9][  0/297]\tTime  1.908 ( 1.908)\tData  1.729 ( 1.729)\tLoss 2.4249e-01 (2.4249e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Test: [  0/102]\tTime  2.666 ( 2.666)\tLoss 1.0897e+00 (1.0897e+00)\tAcc@1  67.97 ( 67.97)\n",
      " * Acc@1 68.114\n",
      "Epoch: [10][  0/297]\tTime  2.483 ( 2.483)\tData  2.321 ( 2.321)\tLoss 2.8770e-01 (2.8770e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Test: [  0/102]\tTime  1.951 ( 1.951)\tLoss 2.9845e-01 (2.9845e-01)\tAcc@1  88.67 ( 88.67)\n",
      " * Acc@1 85.409\n",
      "Epoch: [11][  0/297]\tTime  2.535 ( 2.535)\tData  2.344 ( 2.344)\tLoss 2.0007e-01 (2.0007e-01)\tAcc@1  92.97 ( 92.97)\n",
      "Test: [  0/102]\tTime  2.398 ( 2.398)\tLoss 5.3549e-01 (5.3549e-01)\tAcc@1  76.95 ( 76.95)\n",
      " * Acc@1 81.183\n",
      "Epoch: [12][  0/297]\tTime  2.099 ( 2.099)\tData  1.959 ( 1.959)\tLoss 3.1588e-01 (3.1588e-01)\tAcc@1  87.50 ( 87.50)\n",
      "Test: [  0/102]\tTime  3.039 ( 3.039)\tLoss 6.3096e-01 (6.3096e-01)\tAcc@1  77.34 ( 77.34)\n",
      " * Acc@1 76.661\n",
      "Epoch: [13][  0/297]\tTime  2.606 ( 2.606)\tData  2.449 ( 2.449)\tLoss 2.6004e-01 (2.6004e-01)\tAcc@1  89.84 ( 89.84)\n",
      "Test: [  0/102]\tTime  2.585 ( 2.585)\tLoss 3.7240e-01 (3.7240e-01)\tAcc@1  84.38 ( 84.38)\n",
      " * Acc@1 85.417\n",
      "Epoch: [14][  0/297]\tTime  2.574 ( 2.574)\tData  2.388 ( 2.388)\tLoss 1.3248e-01 (1.3248e-01)\tAcc@1  94.92 ( 94.92)\n",
      "Test: [  0/102]\tTime  2.507 ( 2.507)\tLoss 1.0351e+00 (1.0351e+00)\tAcc@1  73.44 ( 73.44)\n",
      " * Acc@1 71.627\n",
      "Epoch: [15][  0/297]\tTime  2.432 ( 2.432)\tData  2.264 ( 2.264)\tLoss 2.5595e-01 (2.5595e-01)\tAcc@1  89.45 ( 89.45)\n",
      "Test: [  0/102]\tTime  2.792 ( 2.792)\tLoss 3.9160e-01 (3.9160e-01)\tAcc@1  83.20 ( 83.20)\n",
      " * Acc@1 85.848\n",
      "Epoch: [16][  0/297]\tTime  2.882 ( 2.882)\tData  2.653 ( 2.653)\tLoss 1.4182e-01 (1.4182e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/102]\tTime  2.128 ( 2.128)\tLoss 4.3111e-01 (4.3111e-01)\tAcc@1  85.55 ( 85.55)\n",
      " * Acc@1 85.925\n",
      "Epoch: [17][  0/297]\tTime  2.834 ( 2.834)\tData  2.629 ( 2.629)\tLoss 2.2402e-01 (2.2402e-01)\tAcc@1  90.62 ( 90.62)\n",
      "Test: [  0/102]\tTime  1.972 ( 1.972)\tLoss 4.2797e-01 (4.2797e-01)\tAcc@1  80.86 ( 80.86)\n",
      " * Acc@1 84.908\n",
      "Epoch: [18][  0/297]\tTime  2.162 ( 2.162)\tData  1.938 ( 1.938)\tLoss 1.6194e-01 (1.6194e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/102]\tTime  1.948 ( 1.948)\tLoss 4.4833e-01 (4.4833e-01)\tAcc@1  83.20 ( 83.20)\n",
      " * Acc@1 85.887\n",
      "Epoch: [19][  0/297]\tTime  3.006 ( 3.006)\tData  2.843 ( 2.843)\tLoss 2.0847e-01 (2.0847e-01)\tAcc@1  91.02 ( 91.02)\n",
      "Test: [  0/102]\tTime  2.872 ( 2.872)\tLoss 3.6378e-01 (3.6378e-01)\tAcc@1  85.55 ( 85.55)\n",
      " * Acc@1 84.739\n",
      "Epoch: [20][  0/297]\tTime  3.056 ( 3.056)\tData  2.890 ( 2.890)\tLoss 2.1138e-01 (2.1138e-01)\tAcc@1  91.80 ( 91.80)\n",
      "Test: [  0/102]\tTime  2.104 ( 2.104)\tLoss 2.4365e-01 (2.4365e-01)\tAcc@1  89.84 ( 89.84)\n",
      " * Acc@1 88.406\n",
      "Epoch: [21][  0/297]\tTime  2.632 ( 2.632)\tData  2.472 ( 2.472)\tLoss 2.2446e-01 (2.2446e-01)\tAcc@1  91.41 ( 91.41)\n",
      "Test: [  0/102]\tTime  1.987 ( 1.987)\tLoss 2.2364e-01 (2.2364e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 88.822\n",
      "Epoch: [22][  0/297]\tTime  2.547 ( 2.547)\tData  2.390 ( 2.390)\tLoss 2.0909e-01 (2.0909e-01)\tAcc@1  91.02 ( 91.02)\n",
      "Test: [  0/102]\tTime  2.218 ( 2.218)\tLoss 3.3621e-01 (3.3621e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 88.691\n",
      "Epoch: [23][  0/297]\tTime  3.103 ( 3.103)\tData  2.913 ( 2.913)\tLoss 2.1481e-01 (2.1481e-01)\tAcc@1  92.58 ( 92.58)\n",
      "Test: [  0/102]\tTime  2.491 ( 2.491)\tLoss 2.6672e-01 (2.6672e-01)\tAcc@1  89.45 ( 89.45)\n",
      " * Acc@1 88.937\n",
      "Epoch: [24][  0/297]\tTime  2.832 ( 2.832)\tData  2.578 ( 2.578)\tLoss 2.0264e-01 (2.0264e-01)\tAcc@1  93.36 ( 93.36)\n",
      "Test: [  0/102]\tTime  2.581 ( 2.581)\tLoss 2.8403e-01 (2.8403e-01)\tAcc@1  88.67 ( 88.67)\n",
      " * Acc@1 88.437\n",
      "Epoch: [25][  0/297]\tTime  2.572 ( 2.572)\tData  2.370 ( 2.370)\tLoss 1.3694e-01 (1.3694e-01)\tAcc@1  94.92 ( 94.92)\n",
      "Test: [  0/102]\tTime  2.580 ( 2.580)\tLoss 3.2740e-01 (3.2740e-01)\tAcc@1  89.45 ( 89.45)\n",
      " * Acc@1 88.298\n",
      "Epoch: [26][  0/297]\tTime  1.895 ( 1.895)\tData  1.552 ( 1.552)\tLoss 1.5262e-01 (1.5262e-01)\tAcc@1  93.75 ( 93.75)\n",
      "Test: [  0/102]\tTime  2.739 ( 2.739)\tLoss 1.9906e-01 (1.9906e-01)\tAcc@1  89.84 ( 89.84)\n",
      " * Acc@1 88.999\n",
      "Epoch: [27][  0/297]\tTime  2.173 ( 2.173)\tData  1.987 ( 1.987)\tLoss 1.4748e-01 (1.4748e-01)\tAcc@1  94.53 ( 94.53)\n",
      "Test: [  0/102]\tTime  2.083 ( 2.083)\tLoss 3.7499e-01 (3.7499e-01)\tAcc@1  85.55 ( 85.55)\n",
      " * Acc@1 89.018\n",
      "Epoch: [28][  0/297]\tTime  2.178 ( 2.178)\tData  2.020 ( 2.020)\tLoss 1.4387e-01 (1.4387e-01)\tAcc@1  94.14 ( 94.14)\n",
      "Test: [  0/102]\tTime  1.944 ( 1.944)\tLoss 2.2054e-01 (2.2054e-01)\tAcc@1  90.62 ( 90.62)\n",
      " * Acc@1 88.945\n",
      "Epoch: [29][  0/297]\tTime  2.368 ( 2.368)\tData  2.224 ( 2.224)\tLoss 1.3776e-01 (1.3776e-01)\tAcc@1  94.92 ( 94.92)\n",
      "Test: [  0/102]\tTime  2.092 ( 2.092)\tLoss 3.2458e-01 (3.2458e-01)\tAcc@1  90.23 ( 90.23)\n",
      " * Acc@1 88.868\n",
      "Test: [ 0/60]\tTime  2.313 ( 2.313)\tLoss 2.7155e-01 (2.7155e-01)\tAcc@1  89.06 ( 89.06)\n",
      " * Acc@1 90.165\n",
      "************* test number 0 ratio 0.8 acc90.1646957397461 *************\n",
      "Epoch: [0][  0/297]\tTime  2.267 ( 2.267)\tData  2.108 ( 2.108)\tLoss 1.0942e+00 (1.0942e+00)\tAcc@1  32.81 ( 32.81)\n",
      "Test: [  0/102]\tTime  2.585 ( 2.585)\tLoss 2.7860e+00 (2.7860e+00)\tAcc@1  31.64 ( 31.64)\n",
      " * Acc@1 30.503\n",
      "Epoch: [1][  0/297]\tTime  2.365 ( 2.365)\tData  2.192 ( 2.192)\tLoss 6.4039e-01 (6.4039e-01)\tAcc@1  71.48 ( 71.48)\n",
      "Test: [  0/102]\tTime  2.566 ( 2.566)\tLoss 2.0938e+00 (2.0938e+00)\tAcc@1  52.34 ( 52.34)\n",
      " * Acc@1 50.275\n",
      "Epoch: [2][  0/297]\tTime  2.027 ( 2.027)\tData  1.874 ( 1.874)\tLoss 7.6374e-01 (7.6374e-01)\tAcc@1  71.48 ( 71.48)\n",
      "Test: [  0/102]\tTime  2.022 ( 2.022)\tLoss 1.9571e+00 (1.9571e+00)\tAcc@1  54.69 ( 54.69)\n",
      " * Acc@1 50.603\n",
      "Epoch: [3][  0/297]\tTime  2.440 ( 2.440)\tData  2.258 ( 2.258)\tLoss 6.2991e-01 (6.2991e-01)\tAcc@1  75.78 ( 75.78)\n",
      "Test: [  0/102]\tTime  2.429 ( 2.429)\tLoss 8.0391e-01 (8.0391e-01)\tAcc@1  71.48 ( 71.48)\n",
      " * Acc@1 71.935\n",
      "Epoch: [4][  0/297]\tTime  2.269 ( 2.269)\tData  2.137 ( 2.137)\tLoss 4.7998e-01 (4.7998e-01)\tAcc@1  81.64 ( 81.64)\n",
      "Test: [  0/102]\tTime  2.338 ( 2.338)\tLoss 2.3902e+00 (2.3902e+00)\tAcc@1  54.30 ( 54.30)\n",
      " * Acc@1 54.139\n",
      "Epoch: [5][  0/297]\tTime  2.656 ( 2.656)\tData  2.480 ( 2.480)\tLoss 3.9138e-01 (3.9138e-01)\tAcc@1  82.42 ( 82.42)\n",
      "Test: [  0/102]\tTime  1.800 ( 1.800)\tLoss 3.1919e+00 (3.1919e+00)\tAcc@1  49.61 ( 49.61)\n",
      " * Acc@1 50.325\n",
      "Epoch: [6][  0/297]\tTime  2.471 ( 2.471)\tData  2.327 ( 2.327)\tLoss 5.0003e-01 (5.0003e-01)\tAcc@1  81.64 ( 81.64)\n",
      "Test: [  0/102]\tTime  2.586 ( 2.586)\tLoss 3.8404e+00 (3.8404e+00)\tAcc@1  59.77 ( 59.77)\n",
      " * Acc@1 50.888\n",
      "Epoch: [7][  0/297]\tTime  1.934 ( 1.934)\tData  1.735 ( 1.735)\tLoss 6.0761e-01 (6.0761e-01)\tAcc@1  78.91 ( 78.91)\n",
      "Test: [  0/102]\tTime  2.115 ( 2.115)\tLoss 1.0154e+01 (1.0154e+01)\tAcc@1  40.23 ( 40.23)\n",
      " * Acc@1 38.465\n",
      "Epoch: [8][  0/297]\tTime  2.461 ( 2.461)\tData  2.299 ( 2.299)\tLoss 3.1286e-01 (3.1286e-01)\tAcc@1  88.28 ( 88.28)\n",
      "Test: [  0/102]\tTime  2.179 ( 2.179)\tLoss 6.2718e-01 (6.2718e-01)\tAcc@1  76.56 ( 76.56)\n",
      " * Acc@1 75.486\n",
      "Epoch: [9][  0/297]\tTime  2.474 ( 2.474)\tData  2.261 ( 2.261)\tLoss 3.3986e-01 (3.3986e-01)\tAcc@1  87.89 ( 87.89)\n",
      "Test: [  0/102]\tTime  2.404 ( 2.404)\tLoss 1.2384e+00 (1.2384e+00)\tAcc@1  72.66 ( 72.66)\n",
      " * Acc@1 74.986\n",
      "Epoch: [10][  0/297]\tTime  3.211 ( 3.211)\tData  3.047 ( 3.047)\tLoss 2.3715e-01 (2.3715e-01)\tAcc@1  92.19 ( 92.19)\n",
      "Test: [  0/102]\tTime  2.550 ( 2.550)\tLoss 4.0700e-01 (4.0700e-01)\tAcc@1  83.59 ( 83.59)\n",
      " * Acc@1 85.004\n",
      "Epoch: [11][  0/297]\tTime  3.159 ( 3.159)\tData  2.953 ( 2.953)\tLoss 2.5013e-01 (2.5013e-01)\tAcc@1  90.23 ( 90.23)\n",
      "Test: [  0/102]\tTime  2.924 ( 2.924)\tLoss 4.6192e-01 (4.6192e-01)\tAcc@1  83.59 ( 83.59)\n",
      " * Acc@1 86.410\n",
      "Epoch: [12][  0/297]\tTime  2.421 ( 2.421)\tData  2.253 ( 2.253)\tLoss 2.0100e-01 (2.0100e-01)\tAcc@1  92.58 ( 92.58)\n",
      "Test: [  0/102]\tTime  2.242 ( 2.242)\tLoss 7.2304e-01 (7.2304e-01)\tAcc@1  83.59 ( 83.59)\n",
      " * Acc@1 81.619\n",
      "Epoch: [13][  0/297]\tTime  2.331 ( 2.331)\tData  2.157 ( 2.157)\tLoss 2.3490e-01 (2.3490e-01)\tAcc@1  91.80 ( 91.80)\n",
      "Test: [  0/102]\tTime  2.331 ( 2.331)\tLoss 6.7738e-01 (6.7738e-01)\tAcc@1  75.39 ( 75.39)\n",
      " * Acc@1 76.203\n",
      "Epoch: [14][  0/297]\tTime  2.401 ( 2.401)\tData  2.205 ( 2.205)\tLoss 2.7234e-01 (2.7234e-01)\tAcc@1  89.06 ( 89.06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fb0c1e0d040>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28535/2138631281.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#         print('lr', optimizer.param_groups[0]['lr'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/seegene/working8/../main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, args)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;31m# measure data loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ratio = [.8, .8, .8]\n",
    "acc_list = []\n",
    "test_acc = []\n",
    "\n",
    "for num in range(len(ratio)) :\n",
    "    args.saved_dir = '../trained_models/resnet8/stomach2_' + str(num) + '/checkpoint.pt'\n",
    "    path = Path(args.saved_dir.split('checkpoint')[0])\n",
    "    path.mkdir(parents=True, exist_ok=True)  \n",
    "    \n",
    "    model = Net()\n",
    "    # model.fc.out_features = 3\n",
    "    model.fc = nn.Linear(64, 3)\n",
    "    torch.nn.init.normal_(model.fc.weight, std=0.01)\n",
    "    torch.nn.init.constant_(model.fc.bias, 0.)    \n",
    "    # model.load_state_dict(default_state_dict)\n",
    "    model.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "#     optimizer = torch.optim.Adam(params, lr=0.01, weight_decay=args.weight_decay)\n",
    "    optimizer = torch.optim.SGD(\n",
    "           params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 15, 20, 25, 30], \n",
    "                                                        gamma=0.3)\n",
    "    # criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_acc1 = 0\n",
    "    acc1 = 0\n",
    "    train_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "#         print('lr', optimizer.param_groups[0]['lr'])\n",
    "        losses = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "        scheduler.step()\n",
    "\n",
    "        # evaluate after every epoch\n",
    "        acc1 = validate(val_loader, model, criterion, args)   \n",
    "        val_acc.append(acc1.item())\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1) \n",
    "\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'scheduler' : scheduler.state_dict(),\n",
    "        }, is_best, filename=args.saved_dir)   \n",
    "        \n",
    "    checkpoint = torch.load(args.saved_dir)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    acc1 = validate(test_loader, model, criterion, args)    \n",
    "    print('************* test number {} ratio {} acc{} *************'.format(num, ratio[num], acc1))    \n",
    "    acc_list.append(val_acc)    \n",
    "    test_acc.append(acc1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc41c0-29ea-4aea-aeea-07a3fc813ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(args.epochs)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.plot(epochs, acc_list[0], linestyle='--')\n",
    "plt.plot(epochs, acc_list[1])\n",
    "plt.plot(epochs, acc_list[2])\n",
    "# plt.plot(epochs, acc_list[3])\n",
    "plt.legend(['.4', '.4', '.4' ])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('val acc')\n",
    "plt.title('val acc with stain augment using resnet18 for stomach')\n",
    "# plt.axis([10, 30, 88, 94])\n",
    "plt.show()\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451bd47-e60e-4ae6-8eed-f8111f3c89e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e500e-7a43-4ad4-a54b-0f89ecd7d654",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
