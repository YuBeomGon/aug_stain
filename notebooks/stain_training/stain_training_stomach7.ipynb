{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e4aaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision \n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from dataset import val_transforms, CDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f1ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict \n",
    "args = easydict.EasyDict({ \"batch_size\": 256, \n",
    "                          \"epochs\": 30, \n",
    "                          \"data\": 0, \n",
    "                          'lr':0.1,\n",
    "                         'momentum':0.9,\n",
    "                         'weight_decay':1e-4,\n",
    "                         'start_epoch':0,\n",
    "                         'gpu':1,\n",
    "                          'workers':48,\n",
    "                         'print_freq':2000,\n",
    "                         'saved_dir':'../trained_models/stain_training_stomach/checkpoint.pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f5ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make saved dir\n",
    "from pathlib import Path\n",
    "path = Path(args.saved_dir.split('checkpoint')[0])\n",
    "path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d1b194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "ngpus_per_node = torch.cuda.device_count()\n",
    "print(ngpus_per_node)\n",
    "GPU_NUM = args.gpu # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c55e114-1622-42c4-9ce1-e1835910c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from augment import *\n",
    "\n",
    "# stain_mat = np.array([[ 0.63854984,  0.25636421, -0.05117216],\n",
    "#  [ 0.72885336,  0.89928835,  0.35397438],\n",
    "#  [ 0.24388358,  0.33553481, -0.92226462]])\n",
    "\n",
    "# stain_mat = np.array([[ 0.48333748, -0.87457766,  0.03871443],\n",
    "#        [ 0.81212054,  0.46445478,  0.35318832],\n",
    "#        [ 0.32687172,  0.13926837, -0.93475088]])\n",
    "\n",
    "# stain_mat = np.array([[ 0.53420104, -0.8391861 , -0.08528147],\n",
    "#        [ 0.79607249,  0.46660234,  0.38413706],\n",
    "#        [ 0.28257426,  0.27306047, -0.91785066]])\n",
    "\n",
    "stain_mat = np.array([[ 0.59851184, -0.18189402, -0.02771543],\n",
    "       [ 0.47783455,  0.01465236,  0.17879342],\n",
    "       [ 0.63844483,  0.09446875, -0.08804648]])\n",
    "\n",
    "inv_mat = LA.inv(stain_mat)\n",
    "\n",
    "def HEColor_augment(img, sigma1=0.1, sigma2=1):\n",
    "    img = 255. - img.astype(float)\n",
    "    sda_img = rgb_to_sda(img)\n",
    "    conv_img = np.matmul(sda_img, inv_mat.T)\n",
    "\n",
    "#     remove scale and add more bias for main axis, axis ratio is about 20 : 2 : 1\n",
    "    for i in range(conv_img.shape[-1]) :\n",
    "        if i == 0 :\n",
    "            alpha = np.random.uniform(1-sigma1, 1+sigma1)\n",
    "#         beta = np.random.uniform(-sigma2, sigma2)\n",
    "            beta = np.random.normal(0, sigma2)   \n",
    "        elif i == 1 :\n",
    "            alpha = 1\n",
    "            beta = np.random.normal(0, sigma2)   \n",
    "        elif i == 2 :\n",
    "            alpha = 1\n",
    "            beta = np.random.normal(0, sigma2*0.5)\n",
    "        conv_img[:,:,i] *= alpha\n",
    "        conv_img[:,:,i] += beta\n",
    "        \n",
    "    aug_img = np.matmul(conv_img, stain_mat.T)\n",
    "#     aug_img = convert_OD_to_RGB(aug_img)\n",
    "    aug_img = sda_to_rgb(aug_img)\n",
    "    \n",
    "    return 255 - np.clip(aug_img, 0, 255)\n",
    "\n",
    "class HEColorAugment(ImageOnlyTransform) :    \n",
    "    def __init__(\n",
    "        self,\n",
    "        sigma1=0.1,\n",
    "        sigma2=3.,\n",
    "        always_apply=False,\n",
    "        p=1.,\n",
    " ):\n",
    "        super(HEColorAugment, self).__init__(always_apply, p)\n",
    "        self.sigma1= sigma1\n",
    "        self.sigma2= sigma2\n",
    "        \n",
    "    def apply(self, img,  **params):\n",
    "        return HEColor_augment(img, self.sigma1, self.sigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e52944",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "from augment import HEColorAugment\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=.7),\n",
    "        A.VerticalFlip(p=.7),\n",
    "        A.RandomRotate90(p=.7)]\n",
    "    ),\n",
    "#     A.RandomResizedCrop(height=IMAGE_SIZE,width=IMAGE_SIZE,scale=[0.95,1.05],ratio=[0.95,1.05],p=0.5),\n",
    "#     A.transforms.ColorJitter(brightness=0.05, contrast=0.1, saturation=0.1, hue=0.05, p=.8),\n",
    "    HEColorAugment(sigma1=0.2, sigma2=1., p=0.8),\n",
    "], p=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "732a5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import albumentations.pytorch\n",
    "import cv2\n",
    "from augment import HEColorAugment, rgb_to_sda\n",
    "\n",
    "class CDataset(Dataset):\n",
    "    def __init__(self, df, defaultpath='/home/beomgon/Dataset/new_patches/', transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.dir = defaultpath\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.df.iloc[idx, 4]\n",
    "#         print(pid)\n",
    "\n",
    "        image = cv2.imread(self.dir + path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         image = (image.astype(np.float32)-128.)/128.\n",
    "        \n",
    "#         if image is uint8, normalization by 255 is done automatically by albumebtation(ToTensor method)\n",
    "        if self.transform:\n",
    "            timage = self.transform(image=image)\n",
    "            image = timage['image']\n",
    "            \n",
    "#         image = rgb_to_sda(image)\n",
    "        \n",
    "        image =  torch.tensor(image, dtype=torch.float32)/255.\n",
    "        #image = (torch.tensor(image, dtype=torch.float32)-128)/128\n",
    "        image = image.permute(2,0,1)\n",
    "            \n",
    "        label = self.df.iloc[idx, 5]\n",
    "        return image, label, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada50d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../dataframe/train_New_Stomach_df.csv')\n",
    "train_dataset = CDataset(train_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/', \n",
    "                         transform=train_transforms)\n",
    "\n",
    "val_df = pd.read_csv('../dataframe/val_New_Stomach_df.csv')\n",
    "val_dataset = CDataset(val_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/',\n",
    "                       transform=val_transforms)  \n",
    "\n",
    "test_df = pd.read_csv('../dataframe/test_New_Stomach_df.csv')\n",
    "test_dataset = CDataset(test_df, defaultpath='/home/beomgon/Dataset/seegene/new_patches/',\n",
    "                        transform=val_transforms)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfca7026",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label, path = next(iter(train_dataset))\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6787059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 48 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size,\n",
    "                          shuffle=True, num_workers=args.workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dffcb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 256, 256])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels, paths = next(iter(train_loader))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f0d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(512, 3)\n",
    "torch.nn.init.normal_(model.fc.weight, std=0.01)\n",
    "torch.nn.init.constant_(model.fc.bias, 0.)\n",
    "default_state_dict = model.state_dict()\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "# optimizer = torch.optim.Adam(params, lr=0.01, weight_decay=args.weight_decay)\n",
    "optimizer = torch.optim.SGD(\n",
    "       params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "optimizer = torch.optim.SGD(params, lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 15, 20, 25, 30], \n",
    "                                                    gamma=0.2)\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0cf189-d9d0-4d14-bcb8-2071d3497b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21047c40-140f-4212-b841-7e9ac1bd7503",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30503/19882597.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# print('lr', optimizer.param_groups[0]['lr'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/seegene/stain_training/../main.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, args)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;31m# measure data loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "ratio = [0., .02, .05, .08, .1]\n",
    "acc_list = []\n",
    "test_acc = []\n",
    "\n",
    "for num in range(len(ratio)) :\n",
    "    args.saved_dir = '../trained_models/resnet/stain_8_' + str(num) + '/checkpoint.pt'\n",
    "    path = Path(args.saved_dir.split('checkpoint')[0])\n",
    "    path.mkdir(parents=True, exist_ok=True)  \n",
    "    args.ratio = ratio[num]\n",
    "    \n",
    "    if num == 0 :\n",
    "        train_transforms = A.Compose([\n",
    "            A.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "            A.OneOf([\n",
    "                A.HorizontalFlip(p=.7),\n",
    "                A.VerticalFlip(p=.7),\n",
    "                A.RandomRotate90(p=.7)]\n",
    "            ),\n",
    "        #     A.transforms.ColorJitter(brightness=0.05, contrast=0.1, saturation=0.1, hue=0.05, p=.8),\n",
    "#             HEColorAugment(sigma1=args.ratio, sigma2=2., p=0.7),\n",
    "        ], p=1.0)\n",
    "    else :\n",
    "        train_transforms = A.Compose([\n",
    "            A.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1),\n",
    "            A.OneOf([\n",
    "                A.HorizontalFlip(p=.7),\n",
    "                A.VerticalFlip(p=.7),\n",
    "                A.RandomRotate90(p=.7)]\n",
    "            ),\n",
    "        #     A.transforms.ColorJitter(brightness=0.05, contrast=0.1, saturation=0.1, hue=0.05, p=.8),\n",
    "            HEColorAugment(sigma1=args.ratio, sigma2=2, p=0.7),\n",
    "        ], p=1.0)        \n",
    "    \n",
    "    model = models.resnet18(pretrained=True)\n",
    "    # model.fc.out_features = 3\n",
    "    model.fc = nn.Linear(512, 3)\n",
    "    model.load_state_dict(default_state_dict)\n",
    "    model.to(device)\n",
    "\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "#     optimizer = torch.optim.Adam(params, lr=0.01, weight_decay=args.weight_decay)\n",
    "    optimizer = torch.optim.SGD(\n",
    "           params, lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5, 10, 15, 20, 25], \n",
    "                                                        gamma=0.2)\n",
    "    # criterion = nn.CrossEntropyLoss(label_smoothing=0.0)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    \n",
    "    best_acc1 = 0\n",
    "    acc1 = 0\n",
    "    train_loss = []\n",
    "    val_acc = []\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        # print('lr', optimizer.param_groups[0]['lr'])\n",
    "        losses = train(train_loader, model, criterion, optimizer, epoch, args)\n",
    "        scheduler.step()\n",
    "\n",
    "        # evaluate after every epoch\n",
    "        acc1 = validate(val_loader, model, criterion, args)   \n",
    "        val_acc.append(acc1.item())\n",
    "\n",
    "        # remember best acc@1 and save checkpoint\n",
    "        is_best = acc1 > best_acc1\n",
    "        best_acc1 = max(acc1, best_acc1) \n",
    "\n",
    "        save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc1,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "            'scheduler' : scheduler.state_dict(),\n",
    "        }, is_best, filename=args.saved_dir)   \n",
    "        \n",
    "    checkpoint = torch.load(args.saved_dir)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    acc1 = validate(test_loader, model, criterion, args)    \n",
    "    print('************* test number {} ratio {} acc{} *************'.format(num, ratio[num], acc1))    \n",
    "    acc_list.append(val_acc)    \n",
    "    test_acc.append(acc1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ededf3a-0b61-46c1-8b29-52a4d5365093",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(args.epochs)\n",
    "plt.rcParams[\"figure.figsize\"] = (8,6)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.plot(epochs, acc_list[0], linestyle='--')\n",
    "plt.plot(epochs, acc_list[1])\n",
    "plt.plot(epochs, acc_list[2])\n",
    "plt.plot(epochs, acc_list[3])\n",
    "plt.plot(epochs, acc_list[4])\n",
    "plt.legend(['0', '.02', '.05', '.08', '.1'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('val acc')\n",
    "plt.title('val acc with different sigma using resnet18 for stomach')\n",
    "# plt.axis([10, 30, 88, 94])\n",
    "plt.show()\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc41c0-29ea-4aea-aeea-07a3fc813ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4142d2-1a76-4db5-9caf-eff9ba27ec23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
